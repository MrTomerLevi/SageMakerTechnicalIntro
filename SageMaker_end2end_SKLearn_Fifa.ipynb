{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop, Train, Optimize and Deploy Scikit-Learn Random Forest to predict Fifa results\n",
    "\n",
    "* Doc https://sagemaker.readthedocs.io/en/stable/using_sklearn.html\n",
    "* SDK https://sagemaker.readthedocs.io/en/stable/sagemaker.sklearn.html\n",
    "* boto3 https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#client\n",
    "\n",
    "In this notebook we show how to use Amazon SageMaker to develop, train, tune and deploy a Scikit-Learn based ML model (Random Forest). More info on Scikit-Learn can be found here https://scikit-learn.org/stable/index.html. We use the Boston Housing dataset, present in Scikit-Learn: https://scikit-learn.org/stable/datasets/index.html#boston-dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-us-east-1-600839245357\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print(\"Using bucket \" + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "We load a dataset from sklearn, split it and send it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('fifa_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beers_tomer</th>\n",
       "      <th>beers_zach</th>\n",
       "      <th>tod</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>morning</td>\n",
       "      <td>tomer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>morning</td>\n",
       "      <td>tomer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>morning</td>\n",
       "      <td>tomer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>mid</td>\n",
       "      <td>zach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>morning</td>\n",
       "      <td>tomer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    beers_tomer  beers_zach      tod winner\n",
       "80            2           2  morning  tomer\n",
       "53            4           1  morning  tomer\n",
       "64            2           5  morning  tomer\n",
       "3             1           4      mid   zach\n",
       "88            5           5  morning  tomer"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       100\n",
       "unique        2\n",
       "top       tomer\n",
       "freq         58\n",
       "Name: winner, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.winner.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = {\"tod\":     {\"morning\": 1, \"mid\": 2, \"evening\": 3},\n",
    "                \"winner\":  {\"tomer\": 1, \"zach\": 2, }}\n",
    "dataframe = dataframe.replace(cleanup_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beers_tomer</th>\n",
       "      <th>beers_zach</th>\n",
       "      <th>tod</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    beers_tomer  beers_zach  tod  winner\n",
       "76            2           4    2       2\n",
       "20            4           2    3       1\n",
       "53            4           1    1       1\n",
       "23            1           2    1       2\n",
       "92            1           5    2       1\n",
       "98            6           4    1       2\n",
       "80            2           2    1       1\n",
       "63            4           1    1       2\n",
       "75            6           5    1       2\n",
       "9             1           5    3       1\n",
       "40            6           2    2       2\n",
       "17            4           4    1       1\n",
       "81            4           2    1       2\n",
       "44            4           1    2       1\n",
       "51            6           3    3       2\n",
       "43            6           2    1       2\n",
       "19            4           1    3       1\n",
       "70            3           3    3       2\n",
       "26            4           1    2       2\n",
       "15            2           6    3       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3) (100,)\n"
     ]
    }
   ],
   "source": [
    "data = dataframe.values\n",
    "# split into inputs and outputs\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train an test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 3) (33, 3) (67,) (33,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beers_tomer', 'beers_zach', 'tod']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fratures = dataframe.columns.to_list()[:-1]\n",
    "fratures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pd.DataFrame(X_train, columns=fratures)\n",
    "trainX[\"target\"] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=fratures)\n",
    "testX[\"target\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beers_tomer</th>\n",
       "      <th>beers_zach</th>\n",
       "      <th>tod</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beers_tomer  beers_zach  tod  target\n",
       "0            4           4    3       1\n",
       "1            5           5    1       1\n",
       "2            6           2    2       2\n",
       "3            1           5    1       1\n",
       "4            4           3    2       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv(\"fifa_train.csv\")\n",
    "testX.to_csv(\"fifa_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "trainpath = sess.upload_data(\n",
    "    path=\"fifa_train.csv\", bucket=bucket, key_prefix=\"sagemaker/sklearncontainer\"\n",
    ")\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path=\"fifa_test.csv\", bucket=bucket, key_prefix=\"sagemaker/sklearncontainer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a *Script Mode* script\n",
    "The below script contains both training and inference functionality and can run both in SageMaker Training hardware or locally (desktop, SageMaker notebook, on prem, etc). Detailed guidance here https://sagemaker.readthedocs.io/en/stable/using_sklearn.html#preparing-the-scikit-learn-training-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# inference function \n",
    "# ---------------------\n",
    "# Before a model can be served, it must be loaded. The SageMaker Scikit-learn model \n",
    "# server loads your model by invoking a model_fn function that you must provide in your script. The model_fn should have the following signature.\n",
    "# SageMaker will inject the directory where your model files and sub-directories, saved by save, have been mounted. \n",
    "# Your model function should return a model object that can be used for model serving.\n",
    "# More details: https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#load-a-model\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "\n",
    "\n",
    "# See: https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#serve-a-model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"extracting arguments\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    # to simplify the demo we don't use all sklearn RandomForest hyperparameters\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=10)\n",
    "    parser.add_argument(\"--min-samples-leaf\", type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"fifa_train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"fifa_test.csv\")\n",
    "    parser.add_argument(\"--features\", type=str)  # in this script we ask user to explicitly name features\n",
    "    parser.add_argument(\"--target\", type=str)  # in this script we ask user to explicitly name the target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"reading data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"building training and testing datasets\")\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target]\n",
    "    y_test = test_df[args.target]\n",
    "\n",
    "    # train\n",
    "    print(\"training model\")\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=args.n_estimators, min_samples_leaf=args.min_samples_leaf, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # print abs error\n",
    "    print(\"validating model\")\n",
    "    abs_err = np.abs(model.predict(X_test) - y_test)\n",
    "\n",
    "    # print couple perf metrics\n",
    "    for q in [10, 50, 90]:\n",
    "        print(\"AE-at-\" + str(q) + \"th-percentile: \" + str(np.percentile(a=abs_err, q=q)))\n",
    "\n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print(\"model persisted at \" + path)\n",
    "    print(args.min_samples_leaf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training\n",
    "Script arguments allows us to remove from the script any SageMaker-specific configuration, and run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting arguments\n",
      "reading data\n",
      "building training and testing datasets\n",
      "training model\n",
      "validating model\n",
      "AE-at-10th-percentile: 0.1548619047619046\n",
      "AE-at-50th-percentile: 0.4226825396825402\n",
      "AE-at-90th-percentile: 0.723268253968254\n",
      "model persisted at ./model.joblib\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "! python script.py --n-estimators 100 \\\n",
    "                   --min-samples-leaf 2 \\\n",
    "                   --model-dir ./ \\\n",
    "                   --train ./ \\\n",
    "                   --test ./ \\\n",
    "                   --features 'beers_tomer beers_zach tod' \\\n",
    "                   --target target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a training job with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_MODE = True  # see: https://github.com/aws-samples/amazon-sagemaker-local-mode\n",
    "\n",
    "DUMMY_IAM_ROLE = 'arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type=\"local\" if LOCAL_MODE else 'ml.m4.xlarge' # \"ml.c5.xlarge\",\n",
    "role=DUMMY_IAM_ROLE if LOCAL_MODE else get_execution_role()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Estimator from the SageMaker Python SDK\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"script.py\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name=\"fifa-scikit\",\n",
    "    metric_definitions=[{\"Name\": \"median-AE\", \"Regex\": \"AE-at-50th-percentile: ([0-9.]+).*$\"}],\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 10,\n",
    "        \"min-samples-leaf\": 3,\n",
    "        \"features\": 'beers_tomer beers_zach tod',\n",
    "        \"target\": \"target\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating g6q26y7lds-algo-1-dfyh9 ... \n",
      "Creating g6q26y7lds-algo-1-dfyh9 ... done\n",
      "Attaching to g6q26y7lds-algo-1-dfyh9\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m 2021-06-21 08:35:33,153 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m 2021-06-21 08:35:33,156 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m 2021-06-21 08:35:33,167 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m 2021-06-21 08:35:33,348 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m 2021-06-21 08:35:33,363 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m 2021-06-21 08:35:33,376 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m 2021-06-21 08:35:33,387 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m \n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m Training Env:\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m \n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m {\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     },\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"current_host\": \"algo-1-dfyh9\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"algo-1-dfyh9\"\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     ],\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"n-estimators\": 10,\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"min-samples-leaf\": 3,\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"features\": \"beers_tomer beers_zach tod\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"target\": \"target\"\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     },\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"train\": {\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         },\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"test\": {\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         }\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     },\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"job_name\": \"fifa-scikit-2021-06-21-08-35-28-195\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"master_hostname\": \"algo-1-dfyh9\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-600839245357/fifa-scikit-2021-06-21-08-35-28-195/source/sourcedir.tar.gz\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"module_name\": \"script\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"current_host\": \"algo-1-dfyh9\",\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m             \"algo-1-dfyh9\"\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m         ]\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     },\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m     \"user_entry_point\": \"script.py\"\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m }\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m \n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m Environment variables:\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m \n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_HOSTS=[\"algo-1-dfyh9\"]\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_HPS={\"features\":\"beers_tomer beers_zach tod\",\"min-samples-leaf\":3,\"n-estimators\":10,\"target\":\"target\"}\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_USER_ENTRY_POINT=script.py\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-dfyh9\",\"hosts\":[\"algo-1-dfyh9\"]}\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_CURRENT_HOST=algo-1-dfyh9\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_MODULE_NAME=script\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-600839245357/fifa-scikit-2021-06-21-08-35-28-195/source/sourcedir.tar.gz\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-dfyh9\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-dfyh9\"],\"hyperparameters\":{\"features\":\"beers_tomer beers_zach tod\",\"min-samples-leaf\":3,\"n-estimators\":10,\"target\":\"target\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"fifa-scikit-2021-06-21-08-35-28-195\",\"log_level\":20,\"master_hostname\":\"algo-1-dfyh9\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-600839245357/fifa-scikit-2021-06-21-08-35-28-195/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-dfyh9\",\"hosts\":[\"algo-1-dfyh9\"]},\"user_entry_point\":\"script.py\"}\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_USER_ARGS=[\"--features\",\"beers_tomer beers_zach tod\",\"--min-samples-leaf\",\"3\",\"--n-estimators\",\"10\",\"--target\",\"target\"]\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_HP_N-ESTIMATORS=10\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_HP_MIN-SAMPLES-LEAF=3\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_HP_FEATURES=beers_tomer beers_zach tod\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m SM_HP_TARGET=target\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m \n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m \n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m /miniconda3/bin/python script.py --features beers_tomer beers_zach tod --min-samples-leaf 3 --n-estimators 10 --target target\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m \n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m \n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m extracting arguments\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m reading data\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m building training and testing datasets\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m training model\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m validating model\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m AE-at-10th-percentile: 0.20235714285714285\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m AE-at-50th-percentile: 0.4753571428571428\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m AE-at-90th-percentile: 0.7043809523809522\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m model persisted at /opt/ml/model/model.joblib\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m 3\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 |\u001b[0m 2021-06-21 08:35:35,214 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mg6q26y7lds-algo-1-dfyh9 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring your own custom model \n",
    "### Anatomy of an Amazon SageMaker container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/03/07/scikit-sagemaker-1.gif\" width=1000 height=1000 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### More details at: https://aws.amazon.com/blogs/machine-learning/train-and-host-scikit-learn-models-in-amazon-sagemaker-by-building-a-scikit-docker-container/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - Launching a tuning job with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the Hyperparameter Tuner\n",
    "from sagemaker.tuner import IntegerParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "    \"n-estimators\": IntegerParameter(20, 100),\n",
    "    \"min-samples-leaf\": IntegerParameter(2, 6),\n",
    "}\n",
    "\n",
    "# create Optimizer\n",
    "Optimizer = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=sklearn_estimator,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    base_tuning_job_name=\"FIFA-RF-tuner\",\n",
    "    objective_type=\"Minimize\",\n",
    "    objective_metric_name=\"median-AE\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"median-AE\", \"Regex\": \"AE-at-50th-percentile: ([0-9.]+).*$\"}\n",
    "    ],  # extract tracked metric from logs with regexp\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer.fit({\"train\": trainpath, \"test\": testpath})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tuner results in a df\n",
    "results = Optimizer.analytics().dataframe()\n",
    "while results.empty:\n",
    "    time.sleep(1)\n",
    "    results = Optimizer.analytics().dataframe()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to a real-time endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to axj68dtz4i-algo-1-u8jaj\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021-06-21 08:47:56,897 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021-06-21 08:47:56,899 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021-06-21 08:47:56,901 INFO - sagemaker-containers - nginx config: \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m worker_processes auto;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m daemon off;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m events {\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m }\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m http {\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   }\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   server {\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m     }\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m     location / {\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m     }\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   }\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m }\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021-06-21 08:47:57,048 INFO - sagemaker-containers - Module script does not provide a setup.py. \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m Generating setup.py\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021-06-21 08:47:57,049 INFO - sagemaker-containers - Generating setup.cfg\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021-06-21 08:47:57,049 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021-06-21 08:47:57,049 INFO - sagemaker-containers - Installing module with the following command:\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m Building wheels for collected packages: script\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   Building wheel for script (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m \u001b[?25h  Created wheel for script: filename=script-1.0.0-py2.py3-none-any.whl size=5128 sha256=31ef4c8e1b4bf632a75f275f782fe8fbcd90463d1a7729e7cb77f7ce68d6ce01\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-l70yd7sg/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m Successfully built script\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m Installing collected packages: script\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m Successfully installed script-1.0.0\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021/06/21 08:47:59 [crit] 15#15: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 172.18.0.1 - - [21/Jun/2021:08:47:59 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.4\"\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m [2021-06-21 08:47:59 +0000] [31] [INFO] Starting gunicorn 20.0.4\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m [2021-06-21 08:47:59 +0000] [31] [INFO] Listening at: unix:/tmp/gunicorn.sock (31)\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m [2021-06-21 08:47:59 +0000] [31] [INFO] Using worker: gevent\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m [2021-06-21 08:47:59 +0000] [34] [INFO] Booting worker with pid: 34\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m [2021-06-21 08:47:59 +0000] [35] [INFO] Booting worker with pid: 35\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021-06-21 08:48:04,710 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "!\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 172.18.0.1 - - [21/Jun/2021:08:48:05 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.4\"\n"
     ]
    }
   ],
   "source": [
    "predictor = sklearn_estimator.deploy(initial_instance_count = 1,\n",
    "                                     instance_type          = instance_type, \n",
    "                                     endpoint_name          = 'FIFA-PREDICTOR',\n",
    "                                     entry_point            = \"script.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 1],\n",
       "       [6, 4, 1],\n",
       "       [2, 2, 3],\n",
       "       [4, 2, 1],\n",
       "       [4, 1, 2],\n",
       "       [4, 4, 1],\n",
       "       [4, 6, 2],\n",
       "       [5, 3, 3],\n",
       "       [5, 6, 3],\n",
       "       [1, 4, 1],\n",
       "       [1, 5, 2],\n",
       "       [1, 5, 3],\n",
       "       [4, 3, 2],\n",
       "       [2, 5, 3],\n",
       "       [6, 3, 3],\n",
       "       [3, 4, 2],\n",
       "       [1, 6, 3],\n",
       "       [4, 1, 2],\n",
       "       [2, 4, 2],\n",
       "       [6, 6, 3],\n",
       "       [2, 4, 2],\n",
       "       [2, 4, 3],\n",
       "       [1, 6, 2],\n",
       "       [4, 4, 2],\n",
       "       [4, 1, 3],\n",
       "       [5, 2, 3],\n",
       "       [1, 4, 3],\n",
       "       [2, 1, 2],\n",
       "       [4, 5, 1],\n",
       "       [1, 2, 2],\n",
       "       [2, 4, 3],\n",
       "       [5, 1, 2],\n",
       "       [3, 1, 3]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.values[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 2021-06-21 08:48:46,385 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "[1.71876623 1.52059524 1.45626623 1.52277778 1.52172619 1.58571429\n",
      " 1.57079365 1.40616883 1.34271645 1.64880952 1.28555556 1.05333333\n",
      " 1.47535714 1.07       1.40616883 1.69845238 1.05333333 1.52172619\n",
      " 1.70845238 1.41354978 1.70845238 1.38702381 1.27603175 1.68809524\n",
      " 1.19875    1.17857143 1.38035714 1.61704004 1.21678571 1.60876623\n",
      " 1.38702381 1.62589286 1.46215909]\n",
      "\u001b[36maxj68dtz4i-algo-1-u8jaj |\u001b[0m 172.18.0.1 - - [21/Jun/2021:08:48:47 +0000] \"POST /invocations HTTP/1.1\" 200 392 \"-\" \"python-urllib3/1.26.4\"\n"
     ]
    }
   ],
   "source": [
    "# the SKLearnPredictor does the serialization from pandas for us\n",
    "print(predictor.predict(testX[fratures]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: invoke with `boto3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: `csv` serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint,\n",
    "    Body=testX[data.feature_names].to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: `npy` serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npy serialization\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# Serialise numpy ndarray as bytes\n",
    "buffer = BytesIO()\n",
    "# Assuming testX is a data frame\n",
    "np.save(buffer, testX[data.feature_names].values)\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint, Body=buffer.getvalue(), ContentType=\"application/x-npy\"\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling our endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "#Let us define a client to play with autoscaling options\n",
    "client = boto3.client('application-autoscaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_id='endpoint/' + predictor.endpoint_name + '/variant/' + 'AllTraffic' # This is the format in which application autoscaling references the endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker', \n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GPUUtilization metric\n",
    "# Or what metric is the inference logic sensitive to (such as GPUUtilization, CPUUtilization, MemoryUtilization, or Invocations) per instance?\n",
    "response = client.put_scaling_policy(\n",
    "    PolicyName='CPUUtil-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 40.0,\n",
    "        'CustomizedMetricSpecification':\n",
    "        {\n",
    "            'MetricName': 'CPUUtilization',  # TODO: why our model is sensetive to CPU (in addition to GPU)\n",
    "            'Namespace': '/aws/sagemaker/Endpoints',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': predictor.endpoint_name},\n",
    "                {'Name': 'VariantName','Value': 'AllTraffic'}\n",
    "            ],\n",
    "            'Statistic': 'Average', # Possible - 'Statistic': 'Average'|'Minimum'|'Maximum'|'SampleCount'|'Sum'\n",
    "            'Unit': 'Percent'\n",
    "        },\n",
    "        'ScaleInCooldown': 30,\n",
    "        'ScaleOutCooldown': 1\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't forget to delete the endpoint !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3.delete_endpoint(EndpointName=predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
